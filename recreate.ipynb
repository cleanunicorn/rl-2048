{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f879fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import cupy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Direction(Enum):\n",
    "    LEFT = 0\n",
    "    UP = 1\n",
    "    RIGHT = 2\n",
    "    DOWN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Game2048Env:\n",
    "    def __init__(self):\n",
    "        self.grid_size = 4\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "        self.spawn_tile()\n",
    "        self.spawn_tile()\n",
    "        self.score = 0\n",
    "        return self.board.copy()\n",
    "    \n",
    "    def spawn_tile(self):\n",
    "        empty = list(zip(*np.where(self.board == 0)))\n",
    "        if empty:\n",
    "            x, y = empty[np.random.randint(len(empty))]\n",
    "            self.board[x, y] = 2 if np.random.random() < 0.9 else 4\n",
    "        \n",
    "    def step(self, action: Direction):\n",
    "        moved, reward = self.move(action.value)\n",
    "        if moved:\n",
    "            self.spawn_tile()\n",
    "        else:\n",
    "            reward = -10  # Penalty for invalid move\n",
    "        done = not self.can_move()\n",
    "        self.score += reward\n",
    "        return self.board.copy(), reward, done, {}\n",
    "    \n",
    "    def move(self, direction):\n",
    "        board = np.copy(self.board)\n",
    "        reward = 0\n",
    "        moved = False\n",
    "\n",
    "        # Rotate board so all moves are left-moves\n",
    "        for _ in range(direction):\n",
    "            board = np.rot90(board)\n",
    "            \n",
    "        for i in range(self.grid_size):\n",
    "            tiles = board[i][board[i] != 0]  # Extract non-zero\n",
    "            merged = []\n",
    "            j = 0\n",
    "            while j < len(tiles):\n",
    "                if j + 1 < len(tiles) and tiles[j] == tiles[j + 1]:\n",
    "                    merged_val = tiles[j] * 2\n",
    "                    reward += merged_val\n",
    "                    merged.append(merged_val)\n",
    "                    j += 2  # Skip next\n",
    "                    moved = True\n",
    "                else:\n",
    "                    merged.append(tiles[j])\n",
    "                    j += 1\n",
    "            # Pad with zeros to the right\n",
    "            merged += [0] * (self.grid_size - len(merged))\n",
    "            # Detect if move or merge happened\n",
    "            if not np.array_equal(board[i], merged):\n",
    "                moved = True\n",
    "            board[i] = merged\n",
    "\n",
    "        # Restore original orientation\n",
    "        for _ in range((4 - direction) % 4):\n",
    "            board = np.rot90(board)\n",
    "            \n",
    "        if moved:\n",
    "            self.board = board\n",
    "\n",
    "        return moved, reward\n",
    "\n",
    "    \n",
    "    def can_move(self):\n",
    "        for direction in range(4):\n",
    "            temp_board = self.board.copy()\n",
    "            moved, _ = self.move(direction)\n",
    "            self.board = temp_board  # Restore original\n",
    "            if moved:\n",
    "                return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game2048Env()\n",
    "state = game.reset()\n",
    "done = False\n",
    "\n",
    "def print_board(board):\n",
    "    for x in board:\n",
    "        print(\"\\t\".join(f\"{v:4}\" for v in x))\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "print_board(state)\n",
    "\n",
    "for _ in range(3):  # Play 10 random moves\n",
    "\n",
    "    action = Direction(np.random.randint(4))  # Random action for demonstration\n",
    "    state, reward, done, _ = game.step(action)\n",
    "\n",
    "    print(f\"Action: {action.name} | Score: {game.score}\")\n",
    "    print(f\"Reward: {reward} | Done: {done}\")\n",
    "    \n",
    "    print_board(state)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11794321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork:\n",
    "    \"\"\"Simple feedforward netural network\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int = 16, hidden_layers: List[int] = [8, 8], output_size: int = 4, empty: bool = False):\n",
    "        if empty:\n",
    "            return\n",
    "        \n",
    "        self.layers = [input_size] + hidden_layers + [output_size]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            weight_matrix = np.random.randn(self.layers[i], self.layers[i+1]) * np.sqrt(2. / self.layers[i])\n",
    "            bias_vector = np.zeros((self.layers[i+1],))\n",
    "            self.weights.append(weight_matrix)\n",
    "            self.biases.append(bias_vector)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Forward pass through the network\"\"\"  \n",
    "        a = x\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = np.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = self.tanh(z)\n",
    "\n",
    "        # Output layer with linear activation\n",
    "        z = np.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        return z\n",
    "    \n",
    "    def mutate(self, mutation_rate: float = 0.1, mutation_strength: float = 0.5):\n",
    "        \"\"\"Mutate the network's weights and biases\"\"\"\n",
    "        for i in range(len(self.weights)):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutation = np.random.randn(*self.weights[i].shape) * mutation_strength\n",
    "                self.weights[i] += mutation\n",
    "                \n",
    "            if random.random() < mutation_rate:\n",
    "                mutation = np.random.randn(*self.biases[i].shape) * mutation_strength\n",
    "                self.biases[i] += mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GameResult:\n",
    "    score: int\n",
    "    max_tile: int\n",
    "    moves: int\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, network: SimpleNeuralNetwork):\n",
    "        self.network = network\n",
    "\n",
    "    def play(self, env: Game2048Env, max_steps: int = 100) -> int:\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        steps = 0\n",
    "\n",
    "        while not done and steps < max_steps:\n",
    "            action = self.next_move(state)\n",
    "\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "\n",
    "        return GameResult(score=total_reward, max_tile=np.max(state), moves=steps)\n",
    "    \n",
    "    def next_move(self, state: np.ndarray) -> Direction:\n",
    "        flat_state = state.flatten() / 2048.0  # Normalize input\n",
    "        q_values = self.network.forward(flat_state)\n",
    "        action = Direction(np.argmax(q_values))  # Choose action with highest Q-value\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1006ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolutionaryOptimizer:\n",
    "    def __init__(\n",
    "            self, \n",
    "            population_size: int = 50, \n",
    "            elite_size: int = 10,\n",
    "            mutation_rate: float = 0.1, \n",
    "            mutation_strength: float = 0.5\n",
    "        ):\n",
    "        self.population_size = population_size\n",
    "        self.elite_size = elite_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.population = [SimpleNeuralNetwork(hidden_layers=[32, 64, 128, 64, 32, 16, 8]) for _ in range(population_size)]\n",
    "\n",
    "    def evaluate(self, env: Game2048Env, games_per_player: int = 5, max_moves: int = 100) -> List[Tuple[SimpleNeuralNetwork, float]]:\n",
    "        results = []\n",
    "        for network in self.population:\n",
    "            player = Player(network)\n",
    "            total_score = 0\n",
    "            for _ in range(games_per_player):\n",
    "                game_result = player.play(env, max_steps=max_moves)\n",
    "                total_score += game_result.score\n",
    "            avg_score = total_score / games_per_player\n",
    "            results.append((network, avg_score))\n",
    "        return results\n",
    "\n",
    "    def select_and_breed(self, evaluated: List[Tuple[SimpleNeuralNetwork, float]]) -> None:\n",
    "        # Sort by score descending\n",
    "        evaluated.sort(key=lambda x: x[1], reverse=True)\n",
    "        elite = evaluated[:self.elite_size] \n",
    "\n",
    "        new_population = []\n",
    "        new_population.extend([net for net, _ in elite])\n",
    "        while len(new_population) < self.population_size:\n",
    "            network = random.choice(elite)[0]\n",
    "            new_population.append(network)  # Keep the best\n",
    "            # hidden_layers = np.random.randint(0, 128, size=np.random.randint(1, 8))\n",
    "            child = SimpleNeuralNetwork()\n",
    "            child.weights = [np.copy(w) for w in network.weights]\n",
    "            child.biases = [np.copy(b) for b in network.biases]\n",
    "            child.mutate(self.mutation_rate, self.mutation_strength)\n",
    "            new_population.append(child)\n",
    "\n",
    "        self.population = new_population[:self.population_size]\n",
    "\n",
    "    def run_generation(self, env: Game2048Env, games_per_player: int = 5) -> float:\n",
    "        evaluated = self.evaluate(env, games_per_player)\n",
    "        avg_score = sum(score for _, score in evaluated) / len(evaluated)\n",
    "        self.select_and_breed(evaluated)\n",
    "        return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6676ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_network = None\n",
    "best_score = 0\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "def main():\n",
    "    env = Game2048Env()\n",
    "    optimizer = EvolutionaryOptimizer(population_size=100, elite_size=50, mutation_rate=0.1, mutation_strength=0.2)\n",
    "    generations = 5000\n",
    "    games_per_player = 10\n",
    "\n",
    "    avg_scores = []\n",
    "\n",
    "    loop_start_time = time.time()\n",
    "\n",
    "    for gen in range(generations):\n",
    "        #start_time = time.time()\n",
    "        avg_score = optimizer.run_generation(env, games_per_player)\n",
    "        avg_scores.append(avg_score)\n",
    "        elapsed_time = time.time() - loop_start_time\n",
    "        average_time_per_iteration = elapsed_time / (gen + 1)\n",
    "        duration = str(timedelta(seconds=(average_time_per_iteration * (generations - gen + 1))))\n",
    "        print(f\"⏳ {duration} | Generation {gen+1}/{generations} - Average Score: {avg_score}\")\n",
    "\n",
    "    global best_network, best_score\n",
    "    evaluated = optimizer.evaluate(env, games_per_player)\n",
    "    best_network, best_score = max(evaluated, key=lambda x: x[1])\n",
    "\n",
    "    # Plot average scores over generations\n",
    "    plt.plot(range(1, generations + 1), avg_scores)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.title('Evolution of Average Score over Generations')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b20920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of playing a game with the best network\n",
    "if best_network:\n",
    "    env = Game2048Env()\n",
    "    player = Player(best_network)\n",
    "    result = player.play(env, max_steps=1000)\n",
    "    print(f\"Best Network played a game - Score: {result.score}, Max Tile: {result.max_tile}, Moves: {result.moves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5afac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if best_network:\n",
    "    env = Game2048Env()\n",
    "    player = Player(best_network)\n",
    "\n",
    "    while True:\n",
    "        board = env.board\n",
    "        print_board(board)\n",
    "        action = player.next_move(board)\n",
    "        print(f\"Action: {action.name}\")\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            print(\"Game Over\")\n",
    "            print_board(state)\n",
    "            break\n",
    "\n",
    "        time.sleep(1)  # Pause for a second to visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
