{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f879fc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import cupy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830f7ddc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print(torch.__version__)\n",
    "# print(torch.backends.mps.is_available())\n",
    "# print(torch.tensor([1,2,3], device='mps'))  # Should succeed on Apple Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ca476d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Direction(Enum):\n",
    "    LEFT = 0\n",
    "    UP = 1\n",
    "    RIGHT = 2\n",
    "    DOWN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8074fd8e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Game2048Env:\n",
    "    def __init__(self):\n",
    "        self.grid_size = 4\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
    "        self.spawn_tile()\n",
    "        self.spawn_tile()\n",
    "        self.score = 0\n",
    "        return self.board.copy()\n",
    "    \n",
    "    def spawn_tile(self):\n",
    "        empty = list(zip(*np.where(self.board == 0)))\n",
    "        if empty:\n",
    "            x, y = empty[np.random.randint(len(empty))]\n",
    "            self.board[x, y] = 2 if np.random.random() < 0.9 else 4\n",
    "        \n",
    "    def step(self, action: Direction):\n",
    "        moved, reward = self.move(action.value)\n",
    "        if moved:\n",
    "            self.spawn_tile()\n",
    "        else:\n",
    "            # Stop if invalid move\n",
    "            return self.board.copy(), reward, True, {}\n",
    "        done = not self.can_move()\n",
    "        self.score += reward\n",
    "        return self.board.copy(), reward, done, {}\n",
    "    \n",
    "    def move(self, direction):\n",
    "        board = np.copy(self.board)\n",
    "        reward = 0\n",
    "        moved = False\n",
    "\n",
    "        # Rotate board so all moves are left-moves\n",
    "        for _ in range(direction):\n",
    "            board = np.rot90(board)\n",
    "            \n",
    "        for i in range(self.grid_size):\n",
    "            tiles = board[i][board[i] != 0]  # Extract non-zero\n",
    "            merged = []\n",
    "            j = 0\n",
    "            while j < len(tiles):\n",
    "                if j + 1 < len(tiles) and tiles[j] == tiles[j + 1]:\n",
    "                    merged_val = tiles[j] * 2\n",
    "                    reward += merged_val\n",
    "                    merged.append(merged_val)\n",
    "                    j += 2  # Skip next\n",
    "                    moved = True\n",
    "                else:\n",
    "                    merged.append(tiles[j])\n",
    "                    j += 1\n",
    "            # Pad with zeros to the right\n",
    "            merged += [0] * (self.grid_size - len(merged))\n",
    "            # Detect if move or merge happened\n",
    "            if not np.array_equal(board[i], merged):\n",
    "                moved = True\n",
    "            board[i] = merged\n",
    "\n",
    "        # Restore original orientation\n",
    "        for _ in range((4 - direction) % 4):\n",
    "            board = np.rot90(board)\n",
    "            \n",
    "        if moved:\n",
    "            self.board = board\n",
    "\n",
    "        return moved, reward\n",
    "\n",
    "    \n",
    "    def can_move(self):\n",
    "        for direction in range(4):\n",
    "            temp_board = self.board.copy()\n",
    "            moved, _ = self.move(direction)\n",
    "            self.board = temp_board  # Restore original\n",
    "            if moved:\n",
    "                return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d8b203",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\t   2\t   0\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "   0\t   0\t   4\t   0\n",
      "--------------------\n",
      "Action: LEFT | Score: 0\n",
      "Reward: 0 | Done: False\n",
      "   2\t   0\t   0\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "   0\t   0\t   2\t   0\n",
      "   4\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: LEFT | Score: 0\n",
      "Reward: 0 | Done: False\n",
      "   2\t   0\t   0\t   0\n",
      "   0\t   0\t   2\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   4\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: LEFT | Score: 0\n",
      "Reward: 0 | Done: False\n",
      "   2\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   4\t   2\t   0\t   0\n",
      "--------------------\n",
      "Action: LEFT | Score: 0\n",
      "Reward: 0 | Done: True\n",
      "   2\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   4\t   2\t   0\t   0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "game = Game2048Env()\n",
    "state = game.reset()\n",
    "done = False\n",
    "\n",
    "def print_board(board):\n",
    "    for x in board:\n",
    "        print(\"\\t\".join(f\"{v:4}\" for v in x))\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "print_board(state)\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:  # Play some random moves\n",
    "\n",
    "    # action = Direction(np.random.randint(4))  # Random action for demonstration\n",
    "    action = Direction.LEFT  # Fixed action for demonstration\n",
    "    state, reward, done, _ = game.step(action)\n",
    "\n",
    "    print(f\"Action: {action.name} | Score: {game.score}\")\n",
    "    print(f\"Reward: {reward} | Done: {done}\")\n",
    "    \n",
    "    print_board(state)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11794321",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    \"\"\"Simple feedforward neural network using PyTorch\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int = 16, hidden_layers: List[int] = [256], output_size: int = 4, empty: bool = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if empty:\n",
    "            return\n",
    "        \n",
    "        # Build layers using PyTorch modules\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Add hidden layers\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.Tanh())\n",
    "            prev_size = hidden_size\n",
    "            \n",
    "        # Add output layer (no activation)\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights using He initialization\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using He initialization\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight, nonlinearity='tanh')\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        # Convert numpy array to tensor if needed\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "        \n",
    "        # Ensure we're on the right device (MPS if available)\n",
    "        device = next(self.parameters()).device\n",
    "        x = x.to(device)\n",
    "        \n",
    "        return self.network(x)\n",
    "    \n",
    "    def mutate(self, mutation_rate: float = 0.1, mutation_strength: float = 0.5):\n",
    "        \"\"\"Mutate the network's weights and biases\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters():\n",
    "                if torch.rand(1).item() < mutation_rate:\n",
    "                    mutation = torch.randn_like(param) * mutation_strength\n",
    "                    param.add_(mutation)\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"Create a copy of the network\"\"\"\n",
    "        new_network = SimpleNeuralNetwork(empty=True)\n",
    "        new_network.network = type(self.network)()\n",
    "        new_network.load_state_dict(self.state_dict())\n",
    "        return new_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0c9cfd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GameResult:\n",
    "    score: int\n",
    "    max_tile: int\n",
    "    moves: int\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, network: SimpleNeuralNetwork):\n",
    "        self.network = network\n",
    "        # Move network to MPS if available\n",
    "        if torch.backends.mps.is_available():\n",
    "            self.network = self.network.to('mps')\n",
    "\n",
    "    def play(self, env: Game2048Env, max_steps: int = 100) -> GameResult:\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        steps = 0\n",
    "\n",
    "        while not done and steps < max_steps:\n",
    "            action = self.next_move(state)\n",
    "\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "\n",
    "        return GameResult(score=total_reward, max_tile=np.max(state), moves=steps)\n",
    "    \n",
    "    def next_move(self, state: np.ndarray) -> Direction:\n",
    "        self.network.eval()  # Set to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            flat_state = state.flatten() / 2048.0  # Normalize input\n",
    "            q_values = self.network.forward(flat_state)\n",
    "            # Convert back to numpy for argmax\n",
    "            if isinstance(q_values, torch.Tensor):\n",
    "                q_values = q_values.cpu().numpy()\n",
    "            action = Direction(np.argmax(q_values))  # Choose action with highest Q-value\n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1006ab4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class EvolutionaryOptimizer:\n",
    "    def __init__(\n",
    "            self, \n",
    "            population_size: int = 50, \n",
    "            elite_size: int = 10,\n",
    "            mutation_rate: float = 0.1, \n",
    "            mutation_strength: float = 0.5,\n",
    "            hidden_layers: List[int] = [32]\n",
    "        ):\n",
    "        self.population_size = population_size\n",
    "        self.elite_size = elite_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        # Create initial population\n",
    "        self.population = []\n",
    "        for _ in range(population_size):\n",
    "            network = SimpleNeuralNetwork(hidden_layers=hidden_layers)\n",
    "            # Move to MPS if available\n",
    "            if torch.backends.mps.is_available():\n",
    "                network = network.to('mps')\n",
    "            self.population.append(network)\n",
    "\n",
    "    def evaluate(self, env: Game2048Env, games_per_player: int = 5, max_steps: int = 100) -> List[Tuple[SimpleNeuralNetwork, float]]:\n",
    "        results = []\n",
    "        for network in self.population:\n",
    "            player = Player(network)\n",
    "            total_score = 0\n",
    "            for _ in range(games_per_player):\n",
    "                game_result = player.play(env, max_steps=max_steps)\n",
    "                total_score += game_result.score\n",
    "            avg_score = total_score / games_per_player\n",
    "            results.append((network, avg_score))\n",
    "        return results\n",
    "\n",
    "    def select_and_breed(self, evaluated: List[Tuple[SimpleNeuralNetwork, float]]) -> None:\n",
    "        # Sort by score descending\n",
    "        evaluated.sort(key=lambda x: x[1], reverse=True)\n",
    "        elite = evaluated[:self.elite_size] \n",
    "\n",
    "        new_population = []\n",
    "        # Keep elite networks\n",
    "        for net, _ in elite:\n",
    "            new_population.append(net)\n",
    "        \n",
    "        # Create offspring by mutating elite networks\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent = random.choice(elite)[0]\n",
    "            \n",
    "            # Create a child by copying the parent's state\n",
    "            child = SimpleNeuralNetwork(hidden_layers=self.hidden_layers)\n",
    "            child.load_state_dict(parent.state_dict())\n",
    "            \n",
    "            # Move to same device as parent\n",
    "            child = child.to(next(parent.parameters()).device)\n",
    "            \n",
    "            # Mutate the child\n",
    "            child.mutate(self.mutation_rate, self.mutation_strength)\n",
    "            new_population.append(child)\n",
    "\n",
    "        self.population = new_population[:self.population_size]\n",
    "\n",
    "    def run_generation(self, env: Game2048Env, games_per_player: int = 5, max_steps: int = 1000) -> float:\n",
    "        evaluated = self.evaluate(env, games_per_player, max_steps=max_steps)\n",
    "        avg_score = sum(score for _, score in evaluated) / len(evaluated)\n",
    "        self.select_and_breed(evaluated)\n",
    "        return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6676ba",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generation 1/100 ===\n",
      "⏳ 0:13:05.874320 | Generation 1/100 - Average Score: 29.247999999999998\n",
      "=== Generation 2/100 ===\n",
      "⏳ 0:13:58.048899 | Generation 2/100 - Average Score: 32.436000000000014\n",
      "=== Generation 3/100 ===\n",
      "⏳ 0:13:53.956931 | Generation 3/100 - Average Score: 30.936000000000007\n",
      "=== Generation 4/100 ===\n",
      "⏳ 0:14:11.353983 | Generation 4/100 - Average Score: 37.17200000000002\n",
      "=== Generation 5/100 ===\n"
     ]
    }
   ],
   "source": [
    "best_network = None\n",
    "best_score = 0\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "def main():\n",
    "    env = Game2048Env()\n",
    "    optimizer = EvolutionaryOptimizer(\n",
    "        population_size=100, \n",
    "        elite_size=50, \n",
    "        mutation_rate=0.1, \n",
    "        mutation_strength=0.3, \n",
    "        hidden_layers=[256, 256, 256]\n",
    "    )\n",
    "    generations = 10\n",
    "    games_per_player = 10\n",
    "    max_steps = 1000\n",
    "\n",
    "    avg_scores = []\n",
    "\n",
    "    loop_start_time = time.time()\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"=== Generation {gen+1}/{generations} ===\")\n",
    "        \n",
    "        avg_score = optimizer.run_generation(env, games_per_player, max_steps)\n",
    "        avg_scores.append(avg_score)\n",
    "        elapsed_time = time.time() - loop_start_time\n",
    "        average_time_per_iteration = elapsed_time / (gen + 1)\n",
    "        duration = str(timedelta(seconds=(average_time_per_iteration * (generations - gen + 1))))\n",
    "        \n",
    "        print(f\"⏳ {duration} | Generation {gen+1}/{generations} - Average Score: {avg_score}\")\n",
    "\n",
    "    global best_network, best_score\n",
    "    evaluated = optimizer.evaluate(env, games_per_player)\n",
    "    best_network, best_score = max(evaluated, key=lambda x: x[1])\n",
    "\n",
    "    # Plot average scores over generations\n",
    "    plt.plot(range(1, generations + 1), avg_scores)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.title('Evolution of Average Score over Generations')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b20920",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played a game - Score: 168, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 156, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 140, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 52, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 232, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 144, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 180, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 184, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 108, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 104, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 272, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 136, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 132, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 144, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 52, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 144, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 72, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 196, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 56, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 160, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 92, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 104, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 68, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 136, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 200, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 116, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 228, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 284, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 120, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 88, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 56, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 4, Max Tile: 4, Moves: 1000\n",
      "Played a game - Score: 236, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 4, Max Tile: 4, Moves: 1000\n",
      "Played a game - Score: 232, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 76, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 120, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 132, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 148, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 76, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 200, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 92, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 272, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 256, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 144, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 172, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 88, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 120, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 28, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 144, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 164, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 196, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 148, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 136, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 212, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 56, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 264, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 64, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 124, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 116, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 120, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 268, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 176, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 56, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 72, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 144, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 76, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 76, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 184, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 136, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 256, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 288, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 172, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 148, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 164, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 204, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 200, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 156, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 28, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 400, Max Tile: 64, Moves: 1000\n",
      "Played a game - Score: 188, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 108, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 208, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 80, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 164, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 148, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 148, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 124, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 252, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 204, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 116, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 184, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 404, Max Tile: 64, Moves: 1000\n",
      "Played a game - Score: 212, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 252, Max Tile: 32, Moves: 1000\n",
      "Played a game - Score: 140, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 4, Max Tile: 4, Moves: 1000\n",
      "Played a game - Score: 120, Max Tile: 16, Moves: 1000\n",
      "Played a game - Score: 16, Max Tile: 8, Moves: 1000\n",
      "Played a game - Score: 148, Max Tile: 16, Moves: 1000\n",
      "Best tile: 64, Best score: 404\n"
     ]
    }
   ],
   "source": [
    "# Playing with the best network\n",
    "if best_network:\n",
    "    best_tile = 0\n",
    "    best_score = 0\n",
    "    for _ in range(100):\n",
    "        env = Game2048Env()\n",
    "        player = Player(best_network)\n",
    "        result = player.play(env, max_steps=1000)\n",
    "        best_tile = result.max_tile if best_tile < result.max_tile else best_tile\n",
    "        best_score = result.score if best_score < result.score else best_score\n",
    "        print(f\"Played a game - Score: {result.score}, Max Tile: {result.max_tile}, Moves: {result.moves}\")\n",
    "    print(f\"Best tile: {best_tile}, Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5afac0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\t   0\t   0\t   0\n",
      "   0\t   0\t   2\t   0\n",
      "   0\t   0\t   0\t   2\n",
      "   0\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: LEFT, Best: 2\n",
      "   0\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   2\t   0\t   2\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 4\n",
      "   4\t   0\t   2\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "   4\t   0\t   0\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 4\n",
      "   0\t   0\t   4\t   2\n",
      "   0\t   0\t   0\t   0\n",
      "   0\t   0\t   0\t   4\n",
      "   0\t   2\t   0\t   0\n",
      "--------------------\n",
      "Action: LEFT, Best: 4\n",
      "   4\t   2\t   2\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "   4\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 4\n",
      "   0\t   0\t   4\t   4\n",
      "   0\t   0\t   0\t   0\n",
      "   0\t   0\t   0\t   4\n",
      "   0\t   0\t   2\t   2\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   8\t   0\t   0\t   0\n",
      "   0\t   0\t   0\t   0\n",
      "   4\t   0\t   0\t   0\n",
      "   4\t   0\t   2\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   0\t   0\t   0\t   8\n",
      "   0\t   0\t   0\t   0\n",
      "   0\t   2\t   0\t   4\n",
      "   0\t   0\t   4\t   2\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   8\t   0\t   0\t   0\n",
      "   2\t   0\t   0\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   4\t   2\t   0\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   0\t   0\t   0\t   8\n",
      "   0\t   2\t   0\t   2\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   0\t   4\t   2\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   8\t   0\t   0\t   0\n",
      "   4\t   0\t   0\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   4\t   2\t   2\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   0\t   0\t   0\t   8\n",
      "   2\t   0\t   0\t   4\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   0\t   4\t   4\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   8\t   0\t   2\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   8\t   0\t   0\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   0\t   0\t   8\t   2\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   2\t   0\t   8\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   8\t   2\t   0\t   2\n",
      "   2\t   4\t   0\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   2\t   8\t   0\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   0\t   4\t   8\t   4\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   0\t   2\t   8\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   4\t   8\t   4\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   2\t   8\t   0\t   2\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   0\t   4\t   8\t   4\n",
      "   0\t   2\t   2\t   4\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   2\t   8\t   2\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   4\t   8\t   4\t   0\n",
      "   4\t   4\t   2\t   0\n",
      "   2\t   4\t   0\t   0\n",
      "   2\t   8\t   2\t   0\n",
      "--------------------\n",
      "Action: RIGHT, Best: 8\n",
      "   2\t   4\t   8\t   4\n",
      "   0\t   0\t   8\t   2\n",
      "   0\t   0\t   2\t   4\n",
      "   0\t   2\t   8\t   2\n",
      "--------------------\n",
      "Action: LEFT, Best: 8\n",
      "   2\t   4\t   8\t   4\n",
      "   8\t   2\t   0\t   0\n",
      "   2\t   4\t   2\t   0\n",
      "   2\t   8\t   2\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 8\n",
      "   2\t   4\t   8\t   4\n",
      "   8\t   2\t   4\t   0\n",
      "   4\t   4\t   0\t   0\n",
      "   0\t   8\t   2\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 8\n",
      "   2\t   4\t   8\t   4\n",
      "   8\t   2\t   4\t   0\n",
      "   4\t   4\t   2\t   0\n",
      "   0\t   8\t   2\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 8\n",
      "   2\t   4\t   8\t   4\n",
      "   8\t   2\t   4\t   0\n",
      "   4\t   4\t   4\t   0\n",
      "   0\t   8\t   0\t   2\n",
      "--------------------\n",
      "Action: UP, Best: 8\n",
      "   2\t   4\t   8\t   4\n",
      "   8\t   2\t   8\t   2\n",
      "   4\t   4\t   0\t   0\n",
      "   2\t   8\t   0\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 16\n",
      "   2\t   4\t  16\t   4\n",
      "   8\t   2\t   0\t   2\n",
      "   4\t   4\t   0\t   0\n",
      "   2\t   8\t   2\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 16\n",
      "   2\t   4\t  16\t   4\n",
      "   8\t   2\t   2\t   2\n",
      "   4\t   4\t   0\t   0\n",
      "   2\t   8\t   2\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 16\n",
      "   2\t   4\t  16\t   4\n",
      "   8\t   2\t   4\t   2\n",
      "   4\t   4\t   2\t   0\n",
      "   2\t   8\t   0\t   0\n",
      "--------------------\n",
      "Action: UP, Best: 16\n",
      "nop\n",
      "   2\t   4\t  16\t   4\n",
      "   8\t   2\t   4\t   2\n",
      "   4\t   4\t   2\t   0\n",
      "   2\t   8\t   0\t   0\n",
      "--------------------\n",
      "   2\t   4\t  16\t   4\n",
      "   8\t   2\t   4\t   2\n",
      "   4\t   4\t   2\t   0\n",
      "   2\t   8\t   0\t   0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if best_network:\n",
    "    env = Game2048Env()\n",
    "    player = Player(best_network)\n",
    "\n",
    "    while True:\n",
    "        board = env.board\n",
    "        print_board(board)\n",
    "        action = player.next_move(board)\n",
    "        prev_state = state.copy()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        print(f\"Action: {action.name}, Best: {np.max(state)}\")\n",
    "        if (prev_state == state).all():\n",
    "            print(\"nop\")\n",
    "            print_board(prev_state)\n",
    "            print_board(state)\n",
    "            break\n",
    "        if done:\n",
    "            print(\"Game Over\")\n",
    "            print_board(state)\n",
    "            break\n",
    "\n",
    "        #time.sleep(.2)  # Pause for a second to visualize\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927375fe-cb93-4ebf-ba18-b58d8c624b2c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: bestnetwork-1759940911.105819.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"bestnetwork-{time.time()}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_network, f)\n",
    "    print(f\"Saved: {f.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
